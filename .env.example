# OpenRouter Configuration
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# ============================================================================
# LLM PROVIDER SELECTION
# ============================================================================
# Choose which LLM backend to use: openrouter | github-copilot | openclaw
# Default: openrouter (recommended for most users)
LLM_PROVIDER=openrouter

# Enable/disable specific providers
OPENROUTER_ENABLED=true
GITHUB_COPILOT_ENABLED=false
OPENCLAW_ENABLED=false

# Fallback configuration (if primary provider fails)
LLM_FALLBACK_ENABLED=true
LLM_FALLBACK_ORDER=openrouter,github-copilot,openclaw

# ============================================================================
# OPENROUTER CONFIGURATION (Default Provider)
# ============================================================================

# Model Configuration (OpenRouter model identifiers)
# See MODERN_MODELS_2026.md for detailed comparison

# 2026 RECOMMENDED FOR GENERATIVE AGENTS:
# DeepSeek-V3.2: GPT-5 class reasoning, exceptional tool use, cost-effective
# Perfect for agentic systems with multi-step reasoning and tool calling
DEFAULT_MODEL=deepseek/deepseek-chat
FAST_MODEL=google/gemini-3-flash
ADVANCED_MODEL=deepseek/deepseek-chat

# ALTERNATIVE: Use Gemini 3 series for best multimodal performance
# DEFAULT_MODEL=google/gemini-3-flash
# FAST_MODEL=google/gemini-3-flash
# ADVANCED_MODEL=google/gemini-3-pro

# Vision-capable models (for image understanding)
# Gemini 3 Flash: Fast, excellent vision, cost-effective (RECOMMENDED)
# Gemini 3 Pro: Best quality, 1M token context, multimodal
# GPT-5: High accuracy, 400K context, premium
# Llama 3.2 Vision: Open source, self-hostable, privacy-focused
VISION_MODEL=google/gemini-3-flash

# ALTERNATIVE OPTIONS (2026):
# For agentic systems: deepseek/deepseek-chat (GPT-5 class, excellent tool use)
# For maximum quality: google/gemini-3-pro or openai/gpt-5
# For open source: meta-llama/llama-3.2-90b-vision
# For multilingual: xai/grok-2-vision
# For legacy: openai/gpt-4-vision-preview (older)

# WHY DEEPSEEK-V3.2?
# - GPT-5 class reasoning at low-medium cost
# - Best-in-class agentic tool-use performance
# - Gold medal IMO/IOI 2025 results
# - DeepSeek Sparse Attention for efficiency
# - Specialized for interactive agent environments

# ============================================================================
# GITHUB COPILOT SDK (Optional Provider)
# ============================================================================
# Requires: GitHub Copilot subscription + @github/copilot-sdk package
# Install: npm install @github/copilot-sdk
# Setup: gh extension install github/gh-copilot

# GitHub Copilot Model (gpt-4, gpt-4-turbo, claude-3-opus, etc.)
GITHUB_COPILOT_MODEL=gpt-4

# Best for: Advanced agentic workflows, code generation, tool orchestration
# Docs: https://github.com/github/copilot-sdk

# ============================================================================
# OPENCLAW (Optional Provider)
# ============================================================================
# Open-source AI automation framework that runs locally
# Install: npm install -g openclaw@latest
# Setup: openclaw onboard --install-daemon

OPENCLAW_BASE_URL=http://localhost:18789

# Best for: Privacy, local execution, custom automations, no API costs
# Docs: https://openclaw.im/

# ============================================================================
# PROVIDER COMPARISON
# ============================================================================
# OpenRouter:     100+ models, simple API, vision support, pay-per-use
# GitHub Copilot: Agentic workflows, persistent memory, requires subscription
# OpenClaw:       Local execution, open source, privacy-focused, free

# See MULTI_PROVIDER_GUIDE.md for detailed comparison and setup instructions

# ============================================================================
# APPLICATION CONFIGURATION
# ============================================================================
KEY_OWNER=Your Name
DEBUG=true

# Server Configuration
BACKEND_PORT=3000
FRONTEND_PORT=8000

# File Paths (relative to project root)
MAZE_ASSETS_LOC=environment/frontend_server/static_dirs/assets
ENV_MATRIX=environment/frontend_server/static_dirs/assets/the_ville/matrix
ENV_VISUALS=environment/frontend_server/static_dirs/assets/the_ville/visuals
FS_STORAGE=environment/frontend_server/storage
FS_TEMP_STORAGE=environment/frontend_server/temp_storage

# Game Configuration
COLLISION_BLOCK_ID=32125
SEC_PER_STEP=10
